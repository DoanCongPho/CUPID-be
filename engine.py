import os
import json
import numpy as np
from datetime import datetime
from scipy.optimize import linear_sum_assignment
from users.models.preference import Preference, UserPreference
from users.models.profile import UserProfile
from django.contrib.auth import get_user_model

# --- C·∫§U H√åNH ---
DATA_DIR = "data_json"
VECTOR_DIM = None  # Will be set after loading preferences
LEARNING_RATE = 0.1 # T·ªëc ƒë·ªô c·∫≠p nh·∫≠t vector (Alpha)

class DatingEngine:
    def __init__(self):
        # L∆∞u tr·ªØ to√†n b·ªô users trong RAM (M√¥ ph·ªèng Database)
        self.users_db = {}
        self.interactions = []
        self.interests_pool = self._load_interests_pool()
        global VECTOR_DIM
        VECTOR_DIM = 1 + len(self.interests_pool)

    def _load_interests_pool(self):
        # Load all preferences from the database, ordered by name
        return list(Preference.objects.order_by('name').values_list('name', flat=True))

    # --- 1. FEATURE ENGINEERING (T·∫†O VECTOR) ---
    def _create_initial_vector(self, profile, user_id=None):
        """
        Chuy·ªÉn th√¥ng tin th√¥ (UserProfile) th√†nh Vector Numpy
        """
        # A. X·ª≠ l√Ω Tu·ªïi (Chu·∫©n h√≥a v·ªÅ 0-1)
        # Gi·∫£ s·ª≠ d·∫£i tu·ªïi t·ª´ 15 ƒë·∫øn 45
        if hasattr(profile, 'date_of_birth') and profile.date_of_birth:
            current_year = datetime.now().year
            age = current_year - profile.date_of_birth.year
        else:
            age = 25  # default
        norm_age = (age - 15) / (45 - 15)
        norm_age = np.clip(norm_age, 0.0, 1.0)

        # B. X·ª≠ l√Ω S·ªü th√≠ch (One-hot Encoding)
        interests_vec = [0.0] * len(self.interests_pool)
        if user_id:
            user_pref_names = set(UserPreference.objects.filter(user_id=user_id).select_related('preference').values_list('preference__name', flat=True))
        else:
            user_pref_names = set(getattr(profile, 'interests', []) or [])
        for idx, interest in enumerate(self.interests_pool):
            if interest in user_pref_names:
                interests_vec[idx] = 1.0
        final_vec = np.array([norm_age] + interests_vec, dtype=np.float32)
        return final_vec

    # --- 2. LOAD DATA ---
    def load_data_from_json(self):
        print("--- ƒêang t·∫£i d·ªØ li·ªáu t·ª´ JSON v√†o Engine ---")
        if not os.path.exists(DATA_DIR):
            print(f"L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {DATA_DIR}")
            return

        files = [f for f in os.listdir(DATA_DIR) if f.endswith('.json')]

        for f_name in files:
            path = os.path.join(DATA_DIR, f_name)
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)

                user_id = data['user_id']

                # T·∫°o vector ban ƒë·∫ßu cho user n√†y
                embedding = self._create_initial_vector(data)

                # L∆∞u v√†o "Database" gi·∫£ l·∫≠p
                self.users_db[user_id] = {
                    "info": data,          # Th√¥ng tin g·ªëc
                    "vector": embedding    # Vector ƒë·ªÉ t√≠nh to√°n
                }

                # Gom rating v√†o list chung ƒë·ªÉ x·ª≠ l√Ω
                for rating in data.get('ratings', []):
                    self.interactions.append({
                        "user_id": user_id,
                        "target_id": rating['target_user_id'],
                        "score": rating['score'],
                        "timestamp": rating.get('timestamp', 0)
                    })

        print(f"‚úÖ ƒê√£ t·∫£i {len(self.users_db)} users v√† {len(self.interactions)} ratings.")

    # --- 3. CORE AI: VECTOR DRIFT (H·ªåC T·ª™ T∆Ø∆†NG T√ÅC) ---
    def run_training_update(self):
        """
        M√¥ ph·ªèng qu√° tr√¨nh h·ªçc: Duy·ªát qua l·ªãch s·ª≠ rating ƒë·ªÉ ch·ªânh s·ª≠a vector
        """
        print("--- ƒêang ch·∫°y c·∫≠p nh·∫≠t Vector (Training) ---")

        # S·∫Øp x·∫øp interaction theo th·ªùi gian (c≈© tr∆∞·ªõc, m·ªõi sau)
        # ƒê·ªÉ m√¥ ph·ªèng ƒë√∫ng qu√° tr√¨nh ph√°t tri·ªÉn s·ªü th√≠ch
        sorted_interactions = sorted(self.interactions, key=lambda x: x['timestamp'])

        total_loss = 0

        for interaction in sorted_interactions:
            u_id = interaction['user_id']
            t_id = interaction['target_id']
            score = interaction['score'] # 1 ƒë·∫øn 5

            # Ki·ªÉm tra xem user c√≤n t·ªìn t·∫°i kh√¥ng
            if u_id not in self.users_db or t_id not in self.users_db:
                continue

            vec_user = self.users_db[u_id]['vector']
            vec_target = self.users_db[t_id]['vector']

            # --- LOGIC C·∫¨P NH·∫¨T VECTOR ---
            # Chu·∫©n h√≥a score: 1->-1.0 (Gh√©t), 3->0.0 (B√¨nh th∆∞·ªùng), 5->1.0 (Th√≠ch)
            normalized_score = (score - 3) / 2.0

            # C√¥ng th·ª©c Drift:
            # Vector_User_M·ªõi = Vector_User_C≈© + LR * Score * (Vector_Target - Vector_User_C≈©)
            # √ù nghƒ©a:
            # - N·∫øu Score > 0 (Th√≠ch): K√©o User v·ªÅ ph√≠a Target
            # - N·∫øu Score < 0 (Gh√©t): ƒê·∫©y User ra xa Target

            delta = vec_target - vec_user
            update_step = LEARNING_RATE * normalized_score * delta

            # C·∫≠p nh·∫≠t
            self.users_db[u_id]['vector'] += update_step

            # (T√πy ch·ªçn) Chu·∫©n h√≥a l·∫°i vector ƒë·ªÉ kh√¥ng b·ªã qu√° l·ªõn (L2 Norm)
            # norm = np.linalg.norm(self.users_db[u_id]['vector'])
            # if norm > 0: self.users_db[u_id]['vector'] /= norm

        print("‚úÖ ƒê√£ c·∫≠p nh·∫≠t xong vector s·ªü th√≠ch cho t·∫•t c·∫£ User!")

    # --- 3.1. XU·∫§T VECTOR RA FILE ---
    def save_vectors_to_json(self, filename="embeddings.json"):
        """
        L∆∞u t·∫•t c·∫£ vector embedding c·ªßa users ra file JSON
        """
        output = {}
        for user_id, user_data in self.users_db.items():
            output[f"user_{user_id}"] = {
                "user_id": user_id,
                "gender": user_data['info']['gender'],
                "year_of_birth": user_data['info']['year_of_birth'],
                "interests": user_data['info']['interests'],
                "embedding_vector": user_data['vector'].tolist()
            }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ ƒê√£ l∆∞u embedding vectors v√†o file: {filename}")

    def save_vectors_to_txt(self, filename="embeddings.txt"):
        """
        L∆∞u t·∫•t c·∫£ vector embedding c·ªßa users ra file TXT
        Format: user_id | gender | year_of_birth | interests | vector
        """
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=" * 100 + "\n")
            f.write("EMBEDDING VECTORS\n")
            f.write("=" * 100 + "\n\n")

            for user_id, user_data in self.users_db.items():
                f.write(f"User ID: {user_id}\n")
                f.write(f"Gender: {user_data['info']['gender']}\n")
                f.write(f"Year of Birth: {user_data['info']['year_of_birth']}\n")
                f.write(f"Interests: {', '.join(user_data['info']['interests'])}\n")
                f.write(f"Embedding Vector ({len(user_data['vector'])} dimensions):\n")
                f.write(f"  {user_data['vector'].tolist()}\n")
                f.write("-" * 100 + "\n\n")

        print(f"‚úÖ ƒê√£ l∆∞u embedding vectors v√†o file: {filename}")

    # --- 4. T√çNH TO√ÅN & G·ª¢I √ù ---
    def _cosine_similarity(self, vec_a, vec_b):
        dot_product = np.dot(vec_a, vec_b)
        norm_a = np.linalg.norm(vec_a)
        norm_b = np.linalg.norm(vec_b)
        if norm_a == 0 or norm_b == 0:
            return 0.0
        return dot_product / (norm_a * norm_b)

    def get_recommendations(self, user_id, top_k=5):
        if user_id not in self.users_db:
            return []

        current_user = self.users_db[user_id]
        my_vector = current_user['vector']
        my_gender = current_user['info']['gender']

        candidates = []

        # Duy·ªát qua t·∫•t c·∫£ user kh√°c
        for other_id, other_data in self.users_db.items():
            # 1. L·ªçc ch√≠nh m√¨nh
            if other_id == user_id: continue

            # 2. L·ªçc Bipartite (Kh√°c gi·ªõi t√≠nh)
            if other_data['info']['gender'] == my_gender: continue

            # (T√πy ch·ªçn) 3. L·ªçc nh·ªØng ng∆∞·ªùi ƒë√£ t·ª´ng rate r·ªìi?
            # ·ªû demo n√†y ta b·ªè qua ƒë·ªÉ xem ƒëi·ªÉm s·ªë thay ƒë·ªïi th·∫ø n√†o

            # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
            similarity = self._cosine_similarity(my_vector, other_data['vector'])

            candidates.append({
                "user_id": other_id,
                "gender": other_data['info']['gender'],
                "interests": other_data['info']['interests'], # ƒê·ªÉ hi·ªÉn th·ªã cho vui
                "match_score": float(similarity)
            })

        # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo match_score
        candidates.sort(key=lambda x: x['match_score'], reverse=True)

        return candidates[:top_k]

    # --- 5. THU·∫¨T TO√ÅN HUNGARIAN (G·ªöI √ù C·∫∂P T·ªêI ∆ØU) ---
    def find_optimal_pairs(self):
        """
        S·ª≠ d·ª•ng thu·∫≠t to√°n Hungarian (Munkres) ƒë·ªÉ gh√©p c·∫∑p t·ªëi ∆∞u
        gi·ªØa nam v√† n·ªØ sao cho t·ªïng ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng l√† l·ªõn nh·∫•t

        Returns:
            List of tuples: [(male_id, female_id, similarity_score), ...]
        """
        print("\n--- ƒêang t√≠nh to√°n gh√©p c·∫∑p t·ªëi ∆∞u b·∫±ng thu·∫≠t to√°n Hungarian ---")

        # Ph√¢n chia users theo gi·ªõi t√≠nh
        males = []
        females = []

        for user_id, user_data in self.users_db.items():
            if user_data['info']['gender'] == 'M':
                males.append(user_id)
            else:
                females.append(user_id)

        print(f"S·ªë nam: {len(males)}, S·ªë n·ªØ: {len(females)}")

        if len(males) == 0 or len(females) == 0:
            print("‚ö†Ô∏è Kh√¥ng ƒë·ªß c·∫£ hai gi·ªõi ƒë·ªÉ gh√©p c·∫∑p!")
            return []

        # T·∫°o ma tr·∫≠n ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng (similarity matrix)
        # K√≠ch th∆∞·ªõc: len(males) x len(females)
        similarity_matrix = np.zeros((len(males), len(females)))

        for i, male_id in enumerate(males):
            male_vector = self.users_db[male_id]['vector']
            for j, female_id in enumerate(females):
                female_vector = self.users_db[female_id]['vector']
                similarity = self._cosine_similarity(male_vector, female_vector)
                similarity_matrix[i, j] = similarity

        # Thu·∫≠t to√°n Hungarian t√¨m MIN, n√™n ta ƒë·∫£o d·∫•u (ho·∫∑c d√πng -similarity)
        # ƒë·ªÉ chuy·ªÉn b√†i to√°n MAX th√†nh MIN
        cost_matrix = -similarity_matrix

        # √Åp d·ª•ng thu·∫≠t to√°n Hungarian
        row_indices, col_indices = linear_sum_assignment(cost_matrix)

        # Thu th·∫≠p k·∫øt qu·∫£
        optimal_pairs = []
        total_score = 0.0

        for i, j in zip(row_indices, col_indices):
            male_id = males[i]
            female_id = females[j]
            similarity = similarity_matrix[i, j]
            total_score += similarity

            optimal_pairs.append({
                'male_id': male_id,
                'male_info': self.users_db[male_id]['info'],
                'female_id': female_id,
                'female_info': self.users_db[female_id]['info'],
                'similarity_score': float(similarity)
            })

        # S·∫Øp x·∫øp theo ƒëi·ªÉm gi·∫£m d·∫ßn ƒë·ªÉ d·ªÖ ƒë·ªçc
        optimal_pairs.sort(key=lambda x: x['similarity_score'], reverse=True)

        print(f"‚úÖ ƒê√£ t√¨m ƒë∆∞·ª£c {len(optimal_pairs)} c·∫∑p gh√©p t·ªëi ∆∞u!")
        print(f"üìä T·ªïng ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng: {total_score:.4f}")
        print(f"üìä ƒêi·ªÉm trung b√¨nh: {total_score/len(optimal_pairs):.4f}")

        return optimal_pairs, total_score

    def print_optimal_pairs(self, optimal_pairs):
        """
        In ra k·∫øt qu·∫£ gh√©p c·∫∑p t·ªëi ∆∞u m·ªôt c√°ch ƒë·∫πp m·∫Øt
        """
        print("\n" + "="*100)
        print("K·∫æT QU·∫¢ GH√âP C·∫∂P T·ªêI ∆ØU (THU·∫¨T TO√ÅN HUNGARIAN)")
        print("="*100 + "\n")

        for idx, pair in enumerate(optimal_pairs, 1):
            print(f"C·∫∑p {idx}: User {pair['male_id']} (Nam) ‚ô• User {pair['female_id']} (N·ªØ)")
            print(f"  üíØ ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng: {pair['similarity_score']:.4f}")
            print(f"  üë® Nam - NƒÉm sinh: {pair['male_info']['year_of_birth']}, S·ªü th√≠ch: {', '.join(pair['male_info']['interests'])}")
            print(f"  üë© N·ªØ - NƒÉm sinh: {pair['female_info']['year_of_birth']}, S·ªü th√≠ch: {', '.join(pair['female_info']['interests'])}")
            print("-" * 100)

    def save_optimal_pairs_to_file(self, optimal_pairs, total_score, filename="optimal_pairs.txt"):
        """
        L∆∞u k·∫øt qu·∫£ gh√©p c·∫∑p t·ªëi ∆∞u ra file
        """
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("="*100 + "\n")
            f.write("K·∫æT QU·∫¢ GH√âP C·∫∂P T·ªêI ∆ØU (THU·∫¨T TO√ÅN HUNGARIAN)\n")
            f.write("="*100 + "\n\n")
            f.write(f"T·ªïng s·ªë c·∫∑p: {len(optimal_pairs)}\n")
            f.write(f"T·ªïng ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng: {total_score:.4f}\n")
            f.write(f"ƒêi·ªÉm trung b√¨nh: {total_score/len(optimal_pairs):.4f}\n\n")
            f.write("="*100 + "\n\n")

            for idx, pair in enumerate(optimal_pairs, 1):
                f.write(f"C·∫∑p {idx}: User {pair['male_id']} (Nam) ‚ô• User {pair['female_id']} (N·ªØ)\n")
                f.write(f"  üíØ ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng: {pair['similarity_score']:.4f}\n")
                f.write(f"  üë® Nam - NƒÉm sinh: {pair['male_info']['year_of_birth']}, S·ªü th√≠ch: {', '.join(pair['male_info']['interests'])}\n")
                f.write(f"  üë© N·ªØ - NƒÉm sinh: {pair['female_info']['year_of_birth']}, S·ªü th√≠ch: {', '.join(pair['female_info']['interests'])}\n")
                f.write("-" * 100 + "\n\n")

        print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ gh√©p c·∫∑p v√†o file: {filename}")

    def save_optimal_pairs_to_json(self, optimal_pairs, total_score, filename="optimal_pairs.json"):
        """
        L∆∞u k·∫øt qu·∫£ gh√©p c·∫∑p t·ªëi ∆∞u ra file JSON (ch·ªâ th√¥ng tin c·∫ßn thi·∫øt)
        """
        output = {
            "total_pairs": len(optimal_pairs),
            "total_similarity_score": round(total_score, 4),
            "average_score": round(total_score / len(optimal_pairs), 4),
            "pairs": []
        }

        for pair in optimal_pairs:
            output["pairs"].append({
                "male_id": pair['male_id'],
                "female_id": pair['female_id'],
                "similarity_score": round(pair['similarity_score'], 4)
            })

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)

        print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ gh√©p c·∫∑p v√†o file JSON: {filename}")

# --- MAIN DEMO ---
if __name__ == "__main__":
    # 1. Kh·ªüi t·∫°o Engine
    engine = DatingEngine()

    # 2. Load d·ªØ li·ªáu t·ª´ file JSON (m√¥ ph·ªèng DB)
    engine.load_data_from_json()

    # 3. L∆∞u vector TR∆Ø·ªöC khi h·ªçc
    print("\n--- L∆∞u Vector TR∆Ø·ªöC khi t∆∞∆°ng t√°c ---")
    engine.save_vectors_to_json("embeddings_before.json")
    engine.save_vectors_to_txt("embeddings_before.txt")

    # 4. Ch·ªçn th·ª≠ 1 user ƒë·ªÉ test (V√≠ d·ª• User ID 0)
    TEST_USER_ID = 0
    print(f"\n=== TR∆Ø·ªöC KHI H·ªåC (User {TEST_USER_ID}) ===")
    recs_before = engine.get_recommendations(TEST_USER_ID)
    for r in recs_before:
        print(f"User {r['user_id']} ({r['gender']}) - Score: {r['match_score']:.4f} - S·ªü th√≠ch: {r['interests']}")

    # 5. Ch·∫°y Training (C·∫≠p nh·∫≠t vector d·ª±a tr√™n rating l·ªãch s·ª≠)
    engine.run_training_update()

    # 6. L∆∞u vector SAU khi h·ªçc
    print("\n--- L∆∞u Vector SAU khi t∆∞∆°ng t√°c ---")
    engine.save_vectors_to_json("embeddings_after.json")
    engine.save_vectors_to_txt("embeddings_after.txt")

    # 7. Ki·ªÉm tra l·∫°i k·∫øt qu·∫£
    print(f"\n=== SAU KHI H·ªåC (User {TEST_USER_ID}) ===")
    recs_after = engine.get_recommendations(TEST_USER_ID)
    for r in recs_after:
        print(f"User {r['user_id']} ({r['gender']}) - Score: {r['match_score']:.4f} - S·ªü th√≠ch: {r['interests']}")

    print("\nNh·∫≠n x√©t: B·∫°n s·∫Ω th·∫•y danh s√°ch g·ª£i √Ω thay ƒë·ªïi. Nh·ªØng ng∆∞·ªùi c√≥ s·ªü th√≠ch t∆∞∆°ng t·ª± nh·ªØng ng∆∞·ªùi m√† User 0 t·ª´ng ch·∫•m 5 sao s·∫Ω c√≥ ƒëi·ªÉm cao h∆°n.")
    print(f"\nüìÅ ƒê√£ t·∫°o 4 files: embeddings_before.json, embeddings_before.txt, embeddings_after.json, embeddings_after.txt")

    # 8. T√¨m c√°c c·∫∑p gh√©p t·ªëi ∆∞u b·∫±ng thu·∫≠t to√°n Hungarian
    print("\n" + "="*100)
    print("B∆Ø·ªöC 8: T√åM C·∫∂P GH√âP T·ªêI ∆ØU")
    print("="*100)
    optimal_pairs, total_score = engine.find_optimal_pairs()

    # 9. Hi·ªÉn th·ªã k·∫øt qu·∫£
    engine.print_optimal_pairs(optimal_pairs)

    # 10. L∆∞u k·∫øt qu·∫£ ra file
    engine.save_optimal_pairs_to_file(optimal_pairs, total_score, "optimal_pairs.txt")
    engine.save_optimal_pairs_to_json(optimal_pairs, total_score, "optimal_pairs.json")

    print("\nüéâ HO√ÄN TH√ÄNH! Thu·∫≠t to√°n Hungarian ƒë√£ t√¨m ra c√°c c·∫∑p gh√©p t·ªëi ∆∞u v·ªõi t·ªïng ƒëi·ªÉm cao nh·∫•t!")